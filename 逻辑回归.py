import numpy as np
import pandas as pd
from matplotlib import pyplot as plt
import numpy.random
import time

data = pd.read_csv("sklearn_data/LogiReg_data.txt", header=None, names=['æˆç»©1', 'æˆç»©2', 'é€šè¿‡'])


# print(pd.value_counts(data['é€šè¿‡']))
# print(data.shape)
# print(data.head())
# data_one=data[data['é€šè¿‡']==1]
# data_two=data[data['é€šè¿‡']==0]
# fig,ax=plt.subplots(figsize=(20,10))
# ax.scatter(data_one['æˆç»©1'],data_one['æˆç»©2'],c='b',s=50,marker='o',label='é€šè¿‡')
# ax.scatter(data_two['æˆç»©1'],data_two['æˆç»©2'],c='r',s=50,marker='x',label='ä¸é€šè¿‡')
# ax.legend()
# ax.set_xlabel('æµ‹è¯•1çš„åˆ†æ•°')
# ax.set_ylabel('æµ‹è¯•2çš„åˆ†æ•°')
# plt.show()
def sigmod(z):
    
    return 1 / (1 + np.exp(-z))


# num=np.arange(-10,10,1)#åˆ›å»ºåˆ†ç±»å™¨ï¼Œåœ¨xè½´ä¸Šè®¾ç½®æ•°å€¼é—´è·ä¸º1ï¼ˆæ¨ªè½´ï¼‰
# fig,ax=plt.subplots(figsize=(12,4))#figsizeè®¾ç½®å›¾å½¢çš„å®½é«˜ï¼Œå…¶ä¸­å®½åº¦ä¸º12ï¼Œé«˜åº¦ä¸º4
# ax.plot(num,sigmod(num),'-r')#é€šè¿‡sigmodå‡½æ•°è®¡ç®—æ¨ªè½´å€¼å¾—å‡ºè¯¥åˆ†ç±»å™¨åœ¨yè½´ä¸Šçš„æ•°å€¼,'-r':çº¿çš„é¢œè‰²
# plt.show()#ç”»å›¾


def model(X, theta):
    #è®¡ç®—æ‰€æœ‰æ ·æœ¬çš„sigmodå€¼
    return sigmod(np.dot(X, theta.T))  # np.dot(X,theta.T):ç®—å‡ºæ¥çš„ç»“æœä¸ºçŸ©é˜µxä¹˜äºçŸ©é˜µtheta.Tçš„å€¼


data.insert(loc=0, column='Ones', value=1)  # æ·»åŠ ä¸€åˆ—åˆ°datafremeå¯¹è±¡ä¸­

orig_data = data.values  # å°†datafremeå¯¹è±¡è½¬åŒ–ä¸ºäºŒç»´æ•°ç»„ndarrayå¯¹è±¡
# print(orig_data)
col = orig_data.shape[1]  # 0ä»£è¡¨è¡Œï¼Œ1ä»£è¡¨åˆ—,ç»“æœç­‰äº4
# print(col)
X = orig_data[:, 0:col - 1]  # è·å–ä»0åˆ—åˆ°ç¬¬ä¸‰åˆ—çš„æ•°æ®,è¿™åŠéƒ¨åˆ†æ•°æ®åšç‰¹å¾å‘é‡
# print(X)
y = orig_data[:, col - 1:]  # è·å–æœ€åä¸€åˆ—æ•°æ®ï¼ˆæœ¬åˆ—æ•°æ®ä¸ºé¢„æµ‹å€¼ï¼‰
# print(Y)
theta = np.zeros([1, 3])  # åˆ›å»ºä¸€è¡Œä¸‰åˆ—é›¶çŸ©é˜µ


# print(theta)
#                                                 n
# æ¢¯åº¦ä¸‹é™è®¡ç®—ï¼ˆæŸå¤±å‡½æ•°ï¼‰     å…¬å¼ä¸ºğ·(â„ğœƒ(ğ‘¥),ğ‘¦)= - âˆ‘ ğ‘¦log(â„ğœƒ(ğ‘¥))âˆ’(1âˆ’ğ‘¦)log(1âˆ’â„ğœƒ(ğ‘¥))
#                                                ğ‘–=1

#                                          n
# æ¢¯åº¦ä¸‹é™è®¡ç®—ï¼ˆæŸå¤±å‡½æ•°ï¼‰     å…¬å¼ä¸ºğ·(ğ‘¦â€™,ğ‘¦)= - âˆ‘ ğ‘¦log(ğ‘¦')âˆ’(1âˆ’ğ‘¦)log(1âˆ’ğ‘¦')
#                                         ğ‘–=1

# æ±‚å¹³å‡æŸå¤±         åˆ™ğ½(ğœƒ)=1/nğ·(â„ğœƒ(ğ‘¥),ğ‘¦)
# å®šä¹‰æŸå¤±å‡½æ•°
def cost(X, y, theta):
    # model(X,theta)ï¼šâ„ğœƒ(ğ‘¥)
    print(X,y,model(X, theta))
    left = np.multiply(-y, np.log(model(X, theta)))  # å…¬å¼ä¸º-ğ‘¦log(â„ğœƒ(ğ‘¥))ï¼Œå…¶ä¸­â„ğœƒ(ğ‘¥)=g(ğœƒ(ğ‘¥))=1/1+eçš„-ğœƒTxæ¬¡å¯†

    right = np.multiply(1 - y, np.log(1 - model(X, theta)))  # å…¬å¼ä¸º(1âˆ’ğ‘¦)log(1âˆ’â„ğœƒ(ğ‘¥))
    # print(left,right)
    return np.sum(left - right) / (len(X))  # æ­¤æ­¥éª¤è½¬æ¢ä¸ºæ¢¯åº¦ä¸‹é™


# print(cost(X,y,theta))
# è®¡ç®—æ¢¯åº¦
#                   âˆ‚ğ½       1   ğ‘›
# å¯¹ğœƒè¿›è¡Œæ±‚å¯¼ï¼Œå…¬å¼ä¸º â€”  = - â€”  âˆ‘ (ğ‘¦ğ‘–âˆ’â„ğœƒ(ğ‘¥ğ‘–))ğ‘¥ğ‘–ğ‘—
#                  âˆ‚ğœƒğ‘—      ğ‘š  ğ‘–=1
# å®šä¹‰æ¢¯åº¦å‡½æ•°

def gradient(X, y, theta):
    grad = np.zeros(theta.shape)  # å®šä¹‰æ¢¯åº¦,å†™ä¸€å ä½ç¬¦ï¼Œå ä½ç¬¦ä»¥0è¿›è¡Œç«™ä½ï¼Œç”Ÿæˆçš„gradä¸º1*3é›¶çŸ©é˜µ

    error = (model(X, theta) - y).ravel()  # â„ğœƒ(ğ‘¥ğ‘–ï¼‰-yi  ravel():å°†çŸ©é˜µaé‡æ–°æ‹‰ä¼¸æˆä¸€ä¸ªå‘é‡ï¼Œæ‹‰ä¼¸åå¯ä»¥é‡æ–°reshapeæˆä¸€ä¸ªæ–°çŸ©é˜µ
    for j in range(len(theta.ravel())):  # ç»™å…¶è®¾å®šæ¢¯åº¦ä¸‹é™3æ¬¡
        term = np.multiply(error, X[:, j])  # æ¢¯åº¦æ¯ä¸‹é™ä¸€æ¬¡ï¼Œå°±å–Xä¸­çš„æ•°æ®å’Œerrorç›¸ä¹˜ä¸€æ¬¡
        # grad[0,j] : å–ç¬¬0ä¸ªä¸‹æ ‡çš„ç¬¬jä¸ªå…ƒç´ 
        grad[0, j] = np.sum(term) / len(X)  # æ›¿æ¢è¯¥å ä½ç¬¦ä¸­çš„0
        # print(j)
        # print(grad[0,j],'65è¡Œ')
        # print(grad,'66è¡Œ')
    return grad


# æ¯”è¾ƒ3ä¸­ä¸åŒæ¢¯åº¦ä¸‹é™æ–¹æ³•
STOP_ITER = 0
STOP_COST = 1
STOP_GRAD = 2


# type ï¼šåœæ­¢ç­–ç•¥  valueä¸ºæœ€å¤§çš„åœæ­¢æ•°ï¼Œthreshold :è¯¥åœæ­¢ç­–ç•¥å¯¹åº”çš„é˜ˆå€¼
def stopCriterion(type, value, threshold):
    # print(value)
    if type == STOP_ITER:  # å¦‚æœåœæ­¢ç­–ç•¥æ˜¯æœ€å¤§è¿­ä»£æ¬¡æ•°
        return value > threshold  # åˆ™è¿”å›valueå¤§äºé˜ˆå€¼
    elif type == STOP_COST:
        return abs(value[-1] - value[-2]) < threshold
    elif type == STOP_GRAD:
        return np.linalg.norm(value) < threshold  # norm:è¡¨ç¤ºèŒƒæ•°


def shuffleData(data):
    np.random.shuffle(data)

    cols = data.shape[1]

    X = data[:, 0:cols - 1]
    y = data[:, cols - 1:]
    return X, y


# shuffleData(orig_data)


n = 100

#theta  # åˆ›å»ºä¸€è¡Œä¸‰åˆ—é›¶çŸ©é˜µ
# data:æ•°æ®  thetaï¼šå‚æ•° batchSizeåŒ¹é…éšæœºä¸‹é™ç®—æ³•ï¼Œæ ¹æ®ç»™å®šçš„å€¼ï¼Œç¡®å®šä½¿ç”¨å“ªç§ç®—æ³• stopTypeï¼šåœæ­¢ç­–ç•¥ threshï¼šç­–ç•¥å¯¹åº”çš„é˜ˆå€¼ï¼Œalphaï¼šå­¦ä¹ ç‡
def descent(data, theta, batchSize, stopType, thresh, alpha):
    init_time = time.time()  # æŸ¥çœ‹æ—¶é—´å¯¹ç»“æœçš„å½±å“
    i = 0  # åˆå§‹åŒ–è¿­ä»£æ¬¡æ•°ï¼Œä»0æ¬¡å¼€å§‹
    k = 0  # åˆå§‹åŒ–ç®—æ³•ï¼Œä»ç¬¬0ä¸ªbatchå¼€å§‹
    X, y = shuffleData(data)  # è·å–æ´—ç‰Œåé‡æ–°è¿”å›çš„Xæ•°æ®é›†ï¼Œyé¢„æµ‹åˆ—ï¼ˆï¼‰
    grad = np.zeros(theta.shape)  # å®šä¹‰ä¸€ä¸ªå ä½ç¬¦ï¼Œä»¥ä¾¿åæœŸä½¿ç”¨
    costs = [cost(X, y, theta)]  # è·å–æŸå¤±å€¼
    while True:
        grad = gradient(X[k:k + batchSize], y[k:k + batchSize], theta)  # è·å–ä¸åŒçš„æ¢¯åº¦ä¸‹é™ç®—æ³•çš„åå¯¼æ•°å€¼
        k += batchSize  # æ¯è·å–ä¸€æ¬¡ï¼Œè¿­ä»£æ¬¡æ•°+1
        if k >= n:  # å¦‚æœbatchæ¬¡æ•°åˆ‡æ¢è¾¾åˆ°100æ¬¡æ—¶ï¼Œé‡æ–°ç»™å…¶åˆå§‹åŒ–
            k = 0  # åˆå§‹åŒ–ç®—æ³•ï¼Œä»0å¼€å§‹åˆ‡æ¢
            X, y = shuffleData(data)  # é‡æ–°æ´—ç‰Œ
        theta = theta - alpha * grad  # å‚æ•°æ›´æ–°ï¼Œæ–°çš„å‚æ•°ç­‰äºæ—§å‚æ•°-å­¦ä¹ ç‡*ä¸‹é™æ¢¯åº¦ï¼ˆåå¯¼æ•°ï¼‰
        costs.append(cost(X, y, theta))  # é€šè¿‡æŸå¤±å‡½æ•°è®¡ç®—æ–°çš„æŸå¤±ï¼Œå¹¶å°†å…¶è¿”å›å‡ºæ¥æ·»åŠ åˆ°costsä¸­ï¼ˆç”¨äºç”»å›¾ï¼‰
        i += 1  # å¯¹è¿­ä»£æ¬¡æ•°+1
        value = 0
        if stopType == STOP_ITER:  # å¦‚æœåœæ­¢ç­–ç•¥ç­‰äºåœæ­¢è¿­ä»£
            value = i  # åˆ™æœ€å¤§è¿­ä»£æ¬¡æ•°å¤åˆ¶ç»™value
        elif stopType == STOP_COST:  # å¦‚æœåœæ­¢ç­–ç•¥ç­‰äºæŸå¤±å‡½æ•°ï¼ˆä¸¤æ¬¡æŸå¤±å‡½æ•°ç›¸å·®æ— å‡ ï¼‰

            value = costs  # åˆ™è¯¥åŒ…å«æ‰€æœ‰æŸå¤±å‡½æ•°å€¼çš„åˆ—è¡¨å¤åˆ¶ç»™value

        elif stopType == STOP_GRAD:  # å¦‚æœåœæ­¢ç­–ç•¥ç­‰äºæ¢¯åº¦ï¼ˆå½“æ¢¯åº¦ä¸‹é™è¶‹è¿‘äº0æ—¶ï¼Œåœæ­¢å›å½’ï¼‰
            value = grad
        if stopCriterion(stopType, value, thresh):  # è¿”å›ç»“æœå¦‚æœä¸ºTrueï¼Œåˆ™ç»“æŸå¾ªç¯
            break
            # è¿”å›æ–°çš„å‚æ•°å€¼ï¼Œæ–°çš„è¿­ä»£æ¬¡æ•°å€¼ï¼Œæ–°çš„æŸå¤±å€¼ï¼Œæ–°çš„æ¢¯åº¦å€¼ï¼Œæ–°çš„æ—¶é—´å€¼
    return theta, i - 1, costs, grad, time.time() - init_time


def runExpe(data, theta, batchSize, stopType, thresh, alpha):
    # è·å–ä¸‹é™åçš„æœ€æ–°å€¼ï¼Œå¹¶èµ‹å€¼æ–°çš„å˜é‡
    # print(batchSize,'122')
    theta, iter, costs, grad, dur = descent(data, theta, batchSize, stopType, thresh, alpha)
    # data[:,1]>2 åˆ¤æ–­æ˜¯å¦ä¸ºTrueï¼Œå¦‚æœä¸ºTrue,åˆ™æ±‚å’Œå¤§äº1ï¼Œå¦‚æœä¸ºFalseåˆ™å°äº1
    name = 'Original' if (data[:, 1] > 2).sum() > 1 else 'Scaled'  # å¦‚æœç¬¬ä¸€åˆ—çš„æ•°æ®å¤§äº2,ä¸”æ±‚å’Œå¤§äº1ï¼Œåˆ™å¼€å§‹è®¡ç®—
    name += 'å­¦ä¹ ç‡ä¸º{} '.format(alpha)
    if batchSize == n:
        strDesctype = 'æ‰¹é‡æ¢¯åº¦ä¸‹é™å¼€å§‹ï¼š'  # ä»å³å¾€å·¦è¿ç®—ï¼Œå…ˆå¤åˆ¶ï¼Œååˆ¤æ–­
    elif batchSize == 1:
        strDesctype = 'éšæœºæ¢¯åº¦ä¸‹é™å¼€å§‹ï¼š'
    else:
        strDesctype = 'å°æ‰¹é‡æ¢¯åº¦ä¸‹é™å¼€å§‹ï¼š{}'.format(stopType)
    name += strDesctype + 'åœæ­¢ä¸‹é™:'
    # print(stopType,STOP_COST,'137')
    if stopType == STOP_ITER:
        strstop = 'æœ€å¤§è¿­ä»£é˜ˆå€¼ä¸º:{}'.format(thresh)
    elif stopType == STOP_COST:
        strstop = 'æœ€å¤§å‡½æ•°æŸå¤±é˜ˆå€¼<{}'.format(thresh)
    else:
        strstop = 'æœ€å¤§æ¢¯åº¦ä¸‹é™<{}'.format(thresh)
    name += strstop
    print(name, '\n')
    return theta


runExpe(orig_data, theta, n, STOP_ITER, thresh=5000, alpha=0.000001)
# runExpe(orig_data, theta, n, STOP_COST, thresh=0.000001, alpha=0.001)
# runExpe(orig_data, theta, n, STOP_GRAD, thresh=0.005, alpha=0.001)
# runExpe(orig_data, theta, 1, STOP_ITER, thresh=5000, alpha=0.001)
# runExpe(orig_data, theta, 1, STOP_ITER, thresh=15000, alpha=0.000002)

from sklearn import preprocessing as pp  # åˆ©ç”¨sklearnå»ºæ¨¡

scale_data = orig_data.copy()
scale_data[:, 1:3] = pp.scale(orig_data[:, 1:3])
theta = runExpe(scale_data, theta, 1, STOP_GRAD, thresh=0.002 / 5, alpha=0.001)  # é˜ˆå€¼ä¸åŒæ—¶ï¼Œå‡†ç¡®ç‡ä¼šè·Ÿç€ç›¸åº”ä¸åŒ


# runExpe(scale_data, theta, n, STOP_GRAD, thresh=0.02, alpha=0.001)
# runExpe(scale_data, theta, 1, STOP_GRAD, thresh=0.002/5, alpha=0.001)
# print(theta)
# è®¾å®šé˜ˆå€¼


def predict(X, theta):
    # print("X:  ",X,"theta: ",theta)
    # è¿™é‡Œè®¾ç½®å¤§äº0.5é€šè¿‡ï¼Œä¸å¤§äº0.5æœªé€šè¿‡
    # å¦‚æœé€šè¿‡åˆ™å°±è¾“å‡º1ï¼Œä¸é€šè¿‡è¾“å‡º0
    return [1 if x >= 0.5 else 0 for x in model(X, theta)]  # model(X,theta):è¿”å›çš„æ˜¯äºŒç»´æ•°ç»„ï¼Œéå†å‡ºçš„ä¸€ç»´æ•°ç»„å¯ä»¥ç›´æ¥è·Ÿæ•°å€¼è¿›è¡Œåˆ¤æ–­


scale_X = scale_data[:, :3]  # è·å–æ•°æ®é›†ç»“æœå‰çš„æ•°æ®

y1 = scale_data[:, 3]  # è·å–æœ€åä¸€åˆ—æ•°æ®é›†ç»“æœ
predictions = predict(scale_X, theta)  # è·å–åŒ…å«é€šè¿‡çš„å’Œä¸é€šè¿‡çš„ä¸€ç»´æ•°ç»„
# print(predictions,'172è¡Œ')
# print(y1,'173è¡Œ')
# for i in zip(predictions,y1):
#     print(i)

# å°†é¢„æµ‹çš„å€¼å’Œæœ€åä¸€åˆ—æ•°æ®é›†ç»“æœé€šè¿‡zip()æ‰“åŒ…ï¼Œéå†ï¼Œå¹¶èµ‹å€¼ç»™ä¸¤ä¸ªå˜é‡ï¼Œå½“é¢„æµ‹å€¼å’Œæœ€åä¸€åˆ—æ•°æ®é›†ç»“æœç›¸ç­‰æ—¶ï¼Œå³ç»™å…¶èµ‹å€¼ä¸º1ï¼Œå¦åˆ™èµ‹å€¼ä¸º0
# è·å–åçš„currentä¸ºä¸€ç»´æ•°ç»„
current = [1 if ((a == 1 and b == 1) or (a == 0 and b == 0)) else 0 for (a, b) in zip(predictions, y1)]

# å°†æ‰€å¾—ç»“æœç›¸åŠ å¹¶é™¤ä»¥è¯¥ä¸€ç»´æ•°ç»„çš„æ€»æ•°ï¼Œå³ä¸ºå‡†ç¡®ç‡(æ­¤é—´map()å‡½æ•°å¯ä»¥ä¸å†™)
# accuracy=(sum(map(int,current))%len(current))
accuracy = (sum(current) % len(current))
print(accuracy)
